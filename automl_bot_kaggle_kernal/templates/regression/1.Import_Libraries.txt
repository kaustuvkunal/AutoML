<text>
<p align="center"> This notebook is automatically generated by Auto ML job using Kaggle APIs</p>

Introduction :
Phases of Data Science Modelling are sequential in nature. Many of the steps inside these phases are generic. Purpose here is to auto generate a baseline using these generic steps. It saves time and assists in further modeling & tuning decisions. Notebook can also used as basic tutorials.

For Source code & usage instruction :
[Refer Here](https://github.com/kaustuvkunal/AutoML/)

Credit:
This is an extension/modification of [Aster](https://github.com/shivam5992/aster/) bot developed by [Shivam B]( https://www.kaggle.com/shivamb/)

Extended Features includes :
- Regression type learning support
- Hyperparameter tuning
- Multiple & varied  model usages
- ModelLeaderBoard and
- Pipeline usage

References: Following contents are also reffered during course of development
- [Kaggle-API](https://github.com/kaggle/kaggle-api/)
- [Mini BOT Challange](https://www.kaggle.com/general/62760/)
- [Winner2:Ankur Singh for Data Geek Bot](https://github.com/Ankur3107/Kaggle-Data-Geek-Bot/)



</text>

<text>

<br/>Learning type : Regression
 
### Table of Contents 

1.  <B>Import Libraries</B>
2.  <B>Read & Explore Data</B>  
        2.1 Fetch Dataset    
        2.2 Dataset Extract   
        2.3 Dataset Summary   
        2.4 Dataset Shape
        2.5 Missing Features count 
        2.6 Segregate Features & Target
3.  <B>Data Visualisation</B>
        3.1 Target Distribution  
        3.2 Correlation-Matrix (For Numeric Features) 
        3.3 Category Distribution (For Categorical Features)
        3.4 Missing Values Distribution
4.  <B>Data Prepration & Cleaning</B>
		4.1 Dropping Additional Features
        4.1 Dropping Less Correlated Numeric Features
        4.2 Missing Values Treatment     
        4.3 Target Skewness Transform
        4.4 One-hot-encoding and PCA Flag Setup      
        4.5 Train Test Split 

5.  <B>Data Modelling</B>
        5.1 Base Models     
            5.1.1 Ridge Regression
            5.1.2 Lesso Regression
            5.1.3 ElasticNet   
            5.1.4 SVM
            5.1.5 KNeighbors    
        5.2 Bagging Models      
            5.2.1 Random Forest    
            5.2.2 Extra Tree       
        5.3 Boosting Models       
            5.3.1 XGBoost     
            5.3.2 LightGBM  
            5.3.3 AdaBoost  
        5.4 Model LeaderBoard
6. <B>Advance Modeling</B>     
        6.1 Voting Regressor (Average)
        6.2 Voting Regressor (Weighted Average)      
        6.3 Stacking Model 
        6.4 Final Model LeaderBoard
7. <B>Submission File</B> 
     
</text>


<text>
##  1. Import Libraries
Load the required libraries  
</text>

<code>

import warnings
warnings.simplefilter(action='ignore')
## modelling libraries

# read & explore Data
import pandas as pd
import numpy as np 
import itertools
import os 

# data visualisation
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline
import matplotlib.pyplot as plt

# data  visualisation & prepration
from sklearn.model_selection import train_test_split


# data modeling
from sklearn.model_selection import cross_val_score
from sklearn.decomposition import PCA
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge
from sklearn.linear_model import Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import ElasticNet
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import ElasticNet
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import ExtraTreesRegressor
from xgboost.sklearn import XGBRegressor
from lightgbm import LGBMRegressor
from sklearn.ensemble import VotingRegressor
from sklearn.ensemble import AdaBoostRegressor
from sklearn.model_selection import RandomizedSearchCV
from mlxtend.regressor import StackingCVRegressor
from sklearn.decomposition import TruncatedSVD

print (" .. libraries imported  ")
</code>




